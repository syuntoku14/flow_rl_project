{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Proximal Policy Optimization Algorithm</h1>\n",
    "<h2><a href=\"https://arxiv.org/abs/1707.06347\">Arxiv</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n",
      "benchmark: figureeight0\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "\n",
    "import ray\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import requests\n",
    "from tqdm import trange\n",
    "\n",
    "from common.multiprocessing_env import SubprocVecEnv\n",
    "from common.utils import *\n",
    "from common.evaluate import *\n",
    "\n",
    "from agent.network import ActorCritic\n",
    "from agent.ppo import ppo_iter, ppo_update\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device   = torch.device(\"cpu\") # \"cuda\" if use_cuda else \"cpu\")\n",
    "print(\"device: {}\".format(device))\n",
    "\n",
    "# Line notify\n",
    "\n",
    "url = \"https://notify-api.line.me/api/notify\"\n",
    "token = '88RzP9jGYYEusPQKqpdWpELln97VxOah7ZIab2MyV1R'\n",
    "headers = {\"Authorization\" : \"Bearer \"+ token}\n",
    "\n",
    "benchmark_name = 'figureeight0'\n",
    "print('benchmark: {}'.format(benchmark_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-04-04_00-12-33_969/logs.\n",
      "Waiting for redis server at 127.0.0.1:39816 to respond...\n",
      "Waiting for redis server at 127.0.0.1:62406 to respond...\n",
      "Starting the Plasma object store with 13.355121049 GB memory using /dev/shm.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '169.237.32.118',\n",
       " 'object_store_addresses': ['/tmp/ray/session_2019-04-04_00-12-33_969/sockets/plasma_store'],\n",
       " 'raylet_socket_names': ['/tmp/ray/session_2019-04-04_00-12-33_969/sockets/raylet'],\n",
       " 'redis_address': '169.237.32.118:39816',\n",
       " 'webui_url': ''}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init(num_cpus=3, include_webui=False, ignore_reinit_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flow.utils.registry import make_create_env\n",
    "benchmark = __import__(\n",
    "    \"flow.benchmarks.%s\" % benchmark_name, fromlist=[\"flow_params\"])\n",
    "flow_params = benchmark.flow_params\n",
    "HORIZON = flow_params['env'].horizon\n",
    "\n",
    "def make_env(create_env):\n",
    "    def _thunk():\n",
    "        env = create_env()\n",
    "        return env\n",
    "    return _thunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Starting SUMO on port 38545\n",
      " Starting SUMO on port 48405\n",
      " Starting SUMO on port 58088\n"
     ]
    }
   ],
   "source": [
    "# Create Environment\n",
    "num_envs = 3\n",
    "create_env, env_name = make_create_env(params=flow_params, version=0)\n",
    "\n",
    "envs = [make_env(create_env) for i in range(num_envs)]\n",
    "envs = SubprocVecEnv(envs)\n",
    "\n",
    "evs = [PolicyEvaluator.remote(create_env) for i in range(num_envs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 6.95237622e-04, 9.05795302e-02,\n",
       "        1.62008102e-01, 2.33436673e-01, 3.04865245e-01, 3.76293816e-01,\n",
       "        4.47722387e-01, 5.19150959e-01, 5.90579530e-01, 6.62008102e-01,\n",
       "        7.33436673e-01, 8.04865245e-01, 8.76293816e-01, 9.47722387e-01],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 6.95237622e-04, 9.05795302e-02,\n",
       "        1.62008102e-01, 2.33436673e-01, 3.04865245e-01, 3.76293816e-01,\n",
       "        4.47722387e-01, 5.19150959e-01, 5.90579530e-01, 6.62008102e-01,\n",
       "        7.33436673e-01, 8.04865245e-01, 8.76293816e-01, 9.47722387e-01],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 6.95237622e-04, 9.05795302e-02,\n",
       "        1.62008102e-01, 2.33436673e-01, 3.04865245e-01, 3.76293816e-01,\n",
       "        4.47722387e-01, 5.19150959e-01, 5.90579530e-01, 6.62008102e-01,\n",
       "        7.33436673e-01, 8.04865245e-01, 8.76293816e-01, 9.47722387e-01]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "envs.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs  = envs.observation_space.shape[0]\n",
    "num_outputs = envs.action_space.shape[0]\n",
    "device_id = ray.put(device)\n",
    "\n",
    "#Hyper params:\n",
    "lr = 5e-4\n",
    "training_iter = 500\n",
    "num_rollouts = 1\n",
    "num_steps = HORIZON * num_rollouts\n",
    "mini_batch_size = 128\n",
    "num_sgd_iter = 10\n",
    "fcnet_hiddens = [100, 50, 25]\n",
    "gae_lambda = 0.97\n",
    "\n",
    "model = ActorCritic(num_inputs, num_outputs, fcnet_hiddens).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "now = datetime.datetime.now()\n",
    "now = str(now).replace(':', '-').replace(' ', '-')\n",
    "now = now[:now.find('.')]\n",
    "result_path = './result/ppo/' + now\n",
    "os.makedirs(result_path)\n",
    "image_path = result_path + '/reward_history.png'\n",
    "\n",
    "test_rewards, num_iters = [], []\n",
    "\n",
    "state = envs.reset()\n",
    "\n",
    "for num_iter in trange(training_iter):\n",
    "    state = envs.reset()\n",
    "    trajectory = {'log_probs':[], 'values':[], 'states':[], \n",
    "                  'actions':[], 'rewards':[], 'masks':[]}\n",
    "\n",
    "    for _ in range(num_steps):\n",
    "        state = torch.FloatTensor(state).to(device)\n",
    "        dist, value = model(state)\n",
    "        action = dist.sample()\n",
    "        next_state, reward, done, _ = envs.step(action.cpu().numpy())\n",
    "        log_prob = dist.log_prob(action)\n",
    "        append_trajectory(trajectory, log_prob, value, state, action, reward, done, device)\n",
    "        state = next_state\n",
    "\n",
    "    if num_iter % 25 == 0:\n",
    "        model_id = ray.put(model)\n",
    "        results_ids = [ev.test_env.remote(device_id, model_id) for ev in evs]\n",
    "        test_reward = np.mean(ray.get(results_ids))\n",
    "        test_rewards.append(test_reward)\n",
    "        num_iters.append(num_iter)\n",
    "        plot_and_save(num_iters, test_rewards, image_path)\n",
    "        model_path = result_path + '/checkpoint' + str(num_iter) + '.pt'\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        send_line(url, headers, 'epoch: {}'.format(num_iter), image_path)\n",
    "       \n",
    "    next_state = torch.FloatTensor(next_state).to(device)\n",
    "    _, next_value = model(next_state)\n",
    "    returns = compute_gae(next_value, trajectory, tau=gae_lambda)\n",
    "    cat_trajectory(trajectory, returns)\n",
    "    \n",
    "    ppo_update(model, optimizer, num_sgd_iter, mini_batch_size, trajectory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ActorCritic(num_inputs, num_outputs, fcnet_hiddens).to(device)\n",
    "\n",
    "model_path = './result/ppo/2019-04-02-02-06-26/checkpoint475.pt'\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "model_id = ray.put(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = make_vis_env(benchmark_name)\n",
    "\n",
    "test_env(env, device, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "varInspector": {
   "cols": {
    "lenName": "50",
    "lenType": "50",
    "lenVar": "50"
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 467.89781800000003,
   "position": {
    "height": "489.716px",
    "left": "1387.27px",
    "right": "20px",
    "top": "170px",
    "width": "250px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
