{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-27 08:16:01,680\tINFO node.py:469 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-05-27_08-16-01_53957/logs.\n",
      "2019-05-27 08:16:01,801\tINFO services.py:407 -- Waiting for redis server at 127.0.0.1:20213 to respond...\n",
      "2019-05-27 08:16:01,947\tINFO services.py:407 -- Waiting for redis server at 127.0.0.1:33246 to respond...\n",
      "2019-05-27 08:16:01,950\tINFO services.py:804 -- Starting Redis shard with 10.0 GB max memory.\n",
      "2019-05-27 08:16:02,005\tINFO node.py:483 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-05-27_08-16-01_53957/logs.\n",
      "2019-05-27 08:16:02,008\tINFO services.py:1427 -- Starting the Plasma object store with 18.23 GB memory using /dev/shm.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '10.138.0.2',\n",
       " 'object_store_address': '/tmp/ray/session_2019-05-27_08-16-01_53957/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2019-05-27_08-16-01_53957/sockets/raylet',\n",
       " 'redis_address': '10.138.0.2:20213',\n",
       " 'webui_url': None}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gym, pickle, argparse, json, logging\n",
    "from copy import deepcopy\n",
    "import ray\n",
    "from meir import MEIRTrainer\n",
    "\n",
    "from ray import tune\n",
    "from ray.rllib.agents.ppo.ppo_policy_graph import PPOPolicyGraph\n",
    "from ray.rllib.agents.ppo.ppo import DEFAULT_CONFIG\n",
    "from ray.rllib.agents import Trainer\n",
    "from ray.rllib.evaluation import PolicyEvaluator, SampleBatch, MultiAgentSampleBatchBuilder\n",
    "from ray.rllib.offline.json_writer import JsonWriter\n",
    "from ray.rllib.offline.json_reader import JsonReader\n",
    "from ray.rllib.evaluation.sample_batch import DEFAULT_POLICY_ID\n",
    "from ray.rllib.evaluation.metrics import collect_metrics\n",
    "from ray.tune.registry import register_env\n",
    "from ray.rllib.utils.annotations import override\n",
    "\n",
    "from flow.utils.registry import make_create_env\n",
    "from flow.utils.rllib import FlowParamsEncoder, get_flow_params\n",
    "logger = logging.getLogger(__name__)\n",
    "ray.init(ignore_reinit_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cpus = 23 \n",
    "num_rollouts = 20\n",
    "horizon = 750\n",
    "gae_lambda = 0.97\n",
    "step_size = 5e-4\n",
    "num_iter = 10\n",
    "benchmark_name = \"multi_merge\"\n",
    "exp_name = \"test_ir\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = deepcopy(DEFAULT_CONFIG)\n",
    "config[\"num_workers\"] = min(num_cpus, num_rollouts)\n",
    "config[\"train_batch_size\"] = horizon * num_rollouts\n",
    "config[\"sample_batch_size\"] = horizon / 2\n",
    "config[\"use_gae\"] = True\n",
    "config[\"horizon\"] = horizon\n",
    "config[\"lambda\"] = gae_lambda\n",
    "config[\"lr\"] = step_size\n",
    "config[\"vf_clip_param\"] = 1e6\n",
    "config[\"num_sgd_iter\"] = 10\n",
    "config['clip_actions'] = False  # FIXME(ev) temporary ray bug\n",
    "config[\"model\"][\"fcnet_hiddens\"] = [128, 64, 32]\n",
    "config[\"observation_filter\"] = \"NoFilter\"\n",
    "config[\"entropy_coeff\"] = 0.0\n",
    "config[\"num_train\"] = 1\n",
    "config[\"expert_path\"] = './expert_sample'\n",
    "\n",
    "\n",
    "benchmark_name = \"multi_merge\"\n",
    "benchmark = __import__(\n",
    "            \"flow.benchmarks.%s\" % benchmark_name, fromlist=[\"flow_params\"])\n",
    "flow_params = benchmark.buffered_obs_flow_params\n",
    "flow_params[\"env\"].additional_params[\"buf_length\"] = 1\n",
    "create_env, env_name = make_create_env(params=flow_params, version=0)\n",
    "env = create_env()\n",
    "register_env(env_name, create_env)\n",
    "\n",
    "default_policy = (PPOPolicyGraph, env.observation_space, env.action_space, {})\n",
    "policy_graph = {DEFAULT_POLICY_ID: default_policy}\n",
    "config[\"multiagent\"] = {\n",
    "        'policy_graphs': policy_graph,\n",
    "        'policy_mapping_fn': tune.function(lambda agent_id: DEFAULT_POLICY_ID)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-27 08:16:51,421\tINFO policy_evaluator.py:311 -- Creating policy evaluation worker 0 on CPU (please ignore any CUDA init errors)\n",
      "/opt/conda/envs/flow-latest/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "2019-05-27 08:16:53,012\tINFO policy_evaluator.py:728 -- Built policy map: {'default_policy': <ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph object at 0x7fd66c2a9e48>}\n",
      "2019-05-27 08:16:53,013\tINFO policy_evaluator.py:729 -- Built preprocessor map: {'default_policy': <ray.rllib.models.preprocessors.NoPreprocessor object at 0x7fd66c2a9b00>}\n",
      "2019-05-27 08:16:53,015\tINFO policy_evaluator.py:343 -- Built filter map: {'default_policy': <ray.rllib.utils.filter.NoFilter object at 0x7fd66c2b44e0>}\n",
      "2019-05-27 08:16:53,557\tWARNING json_reader.py:52 -- Treating input directory as glob pattern: /headless/rl_project/flow_codes/ModelBased/expert_sample/*.json\n",
      "2019-05-27 08:16:53,559\tINFO json_reader.py:65 -- Found 1 input files.\n"
     ]
    }
   ],
   "source": [
    "agent = MEIRTrainer(config, env_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('1buf.wgt', 'rb') as f:\n",
    "    weights = pickle.load(f)\n",
    "    weights[DEFAULT_POLICY_ID] = weights.pop('default')\n",
    "agent.set_weights(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = JsonWriter(\"./expert_sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m 2019-05-27 08:17:13,208\tINFO policy_evaluator.py:437 -- Generating sample batch of size 375.0\n",
      "\u001b[2m\u001b[36m(pid=55592)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55592)\u001b[0m Success.\n",
      "\u001b[2m\u001b[36m(pid=55587)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55587)\u001b[0m Success.\n",
      "\u001b[2m\u001b[36m(pid=55579)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55579)\u001b[0m Success.\n",
      "\u001b[2m\u001b[36m(pid=55539)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55539)\u001b[0m Success.\n",
      "\u001b[2m\u001b[36m(pid=55573)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55573)\u001b[0m Success.\n",
      "\u001b[2m\u001b[36m(pid=55553)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55553)\u001b[0m Success.\n",
      "\u001b[2m\u001b[36m(pid=55555)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55555)\u001b[0m Success.\n",
      "\u001b[2m\u001b[36m(pid=55567)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55567)\u001b[0m Success.\n",
      "\u001b[2m\u001b[36m(pid=55540)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55540)\u001b[0m Success.\n",
      "\u001b[2m\u001b[36m(pid=55538)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55538)\u001b[0m Success.\n",
      "\u001b[2m\u001b[36m(pid=55571)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55571)\u001b[0m Success.\n",
      "\u001b[2m\u001b[36m(pid=55572)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55572)\u001b[0m Success.\n",
      "\u001b[2m\u001b[36m(pid=55590)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55590)\u001b[0m Success.\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m Success.\n",
      "\u001b[2m\u001b[36m(pid=55565)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55565)\u001b[0m Success.\n",
      "\u001b[2m\u001b[36m(pid=55568)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55568)\u001b[0m Success.\n",
      "\u001b[2m\u001b[36m(pid=55589)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55589)\u001b[0m Success.\n",
      "\u001b[2m\u001b[36m(pid=55556)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55556)\u001b[0m Success.\n",
      "\u001b[2m\u001b[36m(pid=55552)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55552)\u001b[0m Success.\n",
      "\u001b[2m\u001b[36m(pid=55569)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55569)\u001b[0m Success.\n",
      "\u001b[2m\u001b[36m(pid=55592)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55587)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55579)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55539)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55573)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55553)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55555)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55567)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55540)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55538)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55571)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55572)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55590)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55565)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55568)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55589)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55556)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55552)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55569)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m 2019-05-27 08:17:14,983\tINFO sampler.py:308 -- Raw obs from env: { 0: { 'flow_1.0': np.ndarray((12,), dtype=float32, min=0.0, max=1.0, mean=0.504),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m        'flow_1.1': np.ndarray((12,), dtype=float32, min=0.008, max=0.794, mean=0.188)}}\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m 2019-05-27 08:17:14,983\tINFO sampler.py:309 -- Info return from env: {0: {'flow_1.0': {}, 'flow_1.1': {}}}\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m 2019-05-27 08:17:14,984\tINFO sampler.py:407 -- Preprocessed obs: np.ndarray((12,), dtype=float32, min=0.008, max=0.794, mean=0.188)\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m 2019-05-27 08:17:14,984\tINFO sampler.py:411 -- Filtered obs: np.ndarray((12,), dtype=float32, min=0.008, max=0.794, mean=0.188)\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m 2019-05-27 08:17:14,986\tINFO sampler.py:525 -- Inputs to compute_actions():\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m { 'default_policy': [ { 'data': { 'agent_id': 'flow_1.1',\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                                   'env_id': 0,\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                                   'info': {},\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                                   'obs': np.ndarray((12,), dtype=float32, min=0.008, max=0.794, mean=0.188),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                                   'prev_action': np.ndarray((1,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                                   'prev_reward': 0.0,\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                                   'rnn_state': []},\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                         'type': 'PolicyEvalData'},\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                       { 'data': { 'agent_id': 'flow_1.0',\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                                   'env_id': 0,\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                                   'info': {},\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                                   'obs': np.ndarray((12,), dtype=float32, min=0.0, max=1.0, mean=0.504),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                                   'prev_action': np.ndarray((1,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                                   'prev_reward': 0.0,\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                                   'rnn_state': []},\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                         'type': 'PolicyEvalData'}]}\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m 2019-05-27 08:17:14,986\tINFO tf_run_builder.py:89 -- Executing TF run without tracing. To dump TF timeline traces to disk, set the TF_TIMELINE_DIR environment variable.\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m 2019-05-27 08:17:15,036\tINFO sampler.py:552 -- Outputs of compute_actions():\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m { 'default_policy': ( np.ndarray((2, 1), dtype=float32, min=0.495, max=0.969, mean=0.732),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                       [],\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                       { 'action_prob': np.ndarray((2,), dtype=float32, min=2.627, max=3.303, mean=2.965),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                         'behaviour_logits': np.ndarray((2, 2), dtype=float32, min=-2.192, max=1.013, mean=-0.639),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                         'vf_preds': np.ndarray((2,), dtype=float32, min=-27.014, max=-10.225, mean=-18.62)})}\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=55571)\u001b[0m Warning: Teleporting vehicle 'flow_0.40'; collision with vehicle 'flow_2.4', lane=':center_1_0', gap=-1.00, time=159.00 stage=move.\n",
      "\u001b[2m\u001b[36m(pid=55571)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55571)\u001b[0m Success.\n",
      "\u001b[2m\u001b[36m(pid=55571)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55579)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55579)\u001b[0m Success.\n",
      "\u001b[2m\u001b[36m(pid=55567)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55567)\u001b[0m Success.\n",
      "\u001b[2m\u001b[36m(pid=55590)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55590)\u001b[0m Success.\n",
      "\u001b[2m\u001b[36m(pid=55579)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55567)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55540)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55540)\u001b[0m Success.\n",
      "\u001b[2m\u001b[36m(pid=55590)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55569)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55569)\u001b[0m Success.\n",
      "\u001b[2m\u001b[36m(pid=55540)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55569)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55592)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55592)\u001b[0m Success.\n",
      "\u001b[2m\u001b[36m(pid=55539)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m 2019-05-27 08:17:19,143\tINFO sample_batch_builder.py:161 -- Trajectory fragment after postprocess_trajectory():\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m { 'flow_1.0': { 'data': { 'action_prob': np.ndarray((27,), dtype=float32, min=0.096, max=4.02, mean=2.331),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'actions': np.ndarray((27, 1), dtype=float32, min=0.791, max=1.824, mean=1.151),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'advantages': np.ndarray((27,), dtype=float32, min=-0.204, max=2.096, mean=0.893),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'agent_index': np.ndarray((27,), dtype=int64, min=1.0, max=1.0, mean=1.0),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'behaviour_logits': np.ndarray((27, 2), dtype=float32, min=-2.327, max=1.561, mean=-0.468),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'dones': np.ndarray((27,), dtype=bool, min=0.0, max=1.0, mean=0.037),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'eps_id': np.ndarray((27,), dtype=int64, min=248781626.0, max=248781626.0, mean=248781626.0),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'infos': np.ndarray((27,), dtype=object, head={'cost2': 0.0, 'cost1': 0.6514673324987896, 'mean_vel': 17.996562297812105, 'outflow': 445.5445544554455}),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'new_obs': np.ndarray((27, 12), dtype=float32, min=0.0, max=1.0, mean=0.523),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'obs': np.ndarray((27, 12), dtype=float32, min=0.0, max=1.0, mean=0.519),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'prev_actions': np.ndarray((27, 1), dtype=float32, min=0.0, max=1.824, mean=1.09),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'prev_rewards': np.ndarray((27,), dtype=float32, min=-0.349, max=0.0, mean=-0.305),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'rewards': np.ndarray((27,), dtype=float32, min=-0.349, max=-0.291, mean=-0.316),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           't': np.ndarray((27,), dtype=int64, min=0.0, max=26.0, mean=13.0),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'unroll_id': np.ndarray((27,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'value_targets': np.ndarray((27,), dtype=float32, min=-8.129, max=-0.304, mean=-4.209),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'vf_preds': np.ndarray((27,), dtype=float32, min=-10.225, max=-1.252, mean=-5.102)},\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                 'type': 'SampleBatch'},\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m   'flow_1.1': { 'data': { 'action_prob': np.ndarray((78,), dtype=float32, min=0.048, max=10.808, mean=3.219),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'actions': np.ndarray((78, 1), dtype=float32, min=0.495, max=1.859, mean=0.949),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'advantages': np.ndarray((78,), dtype=float32, min=-0.046, max=7.838, mean=2.894),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'agent_index': np.ndarray((78,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'behaviour_logits': np.ndarray((78, 2), dtype=float32, min=-3.503, max=1.523, mean=-0.686),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'dones': np.ndarray((78,), dtype=bool, min=0.0, max=1.0, mean=0.013),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'eps_id': np.ndarray((78,), dtype=int64, min=248781626.0, max=248781626.0, mean=248781626.0),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'infos': np.ndarray((78,), dtype=object, head={'cost2': 0.0, 'cost1': 0.6514673324987896, 'mean_vel': 17.996562297812105, 'outflow': 445.5445544554455}),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'new_obs': np.ndarray((78, 12), dtype=float32, min=-0.002, max=1.0, mean=0.403),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'obs': np.ndarray((78, 12), dtype=float32, min=-0.002, max=1.0, mean=0.398),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'prev_actions': np.ndarray((78, 1), dtype=float32, min=0.0, max=1.859, mean=0.929),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'prev_rewards': np.ndarray((78,), dtype=float32, min=-0.394, max=0.0, mean=-0.344),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'rewards': np.ndarray((78,), dtype=float32, min=-0.394, max=-0.291, mean=-0.349),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           't': np.ndarray((78,), dtype=int64, min=0.0, max=77.0, mean=38.5),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'unroll_id': np.ndarray((78,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'value_targets': np.ndarray((78,), dtype=float32, min=-23.729, max=-0.388, mean=-13.217),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'vf_preds': np.ndarray((78,), dtype=float32, min=-27.014, max=-1.451, mean=-16.111)},\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                 'type': 'SampleBatch'},\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m   'flow_1.2': { 'data': { 'action_prob': np.ndarray((121,), dtype=float32, min=0.045, max=9.357, mean=2.472),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'actions': np.ndarray((121, 1), dtype=float32, min=-1.634, max=1.843, mean=0.714),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'advantages': np.ndarray((121,), dtype=float32, min=-1.667, max=6.398, mean=0.634),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'agent_index': np.ndarray((121,), dtype=int64, min=2.0, max=2.0, mean=2.0),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'behaviour_logits': np.ndarray((121, 2), dtype=float32, min=-3.234, max=1.563, mean=-0.601),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'dones': np.ndarray((121,), dtype=bool, min=0.0, max=1.0, mean=0.008),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'eps_id': np.ndarray((121,), dtype=int64, min=248781626.0, max=248781626.0, mean=248781626.0),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'infos': np.ndarray((121,), dtype=object, head={'cost2': 0.0, 'cost1': 0.6838525318389594, 'mean_vel': 18.73346213645899, 'outflow': 465.5172413793103}),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'new_obs': np.ndarray((121, 12), dtype=float32, min=-0.182, max=1.0, mean=0.372),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'obs': np.ndarray((121, 12), dtype=float32, min=-0.182, max=1.0, mean=0.37),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'prev_actions': np.ndarray((121, 1), dtype=float32, min=-1.634, max=1.843, mean=0.7),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'prev_rewards': np.ndarray((121,), dtype=float32, min=-0.412, max=-0.291, mean=-0.375),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'rewards': np.ndarray((121,), dtype=float32, min=-0.412, max=-0.291, mean=-0.376),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           't': np.ndarray((121,), dtype=int64, min=15.0, max=135.0, mean=75.0),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'unroll_id': np.ndarray((121,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'value_targets': np.ndarray((121,), dtype=float32, min=-27.504, max=-0.387, mean=-16.839),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'vf_preds': np.ndarray((121,), dtype=float32, min=-32.997, max=-1.222, mean=-17.473)},\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                 'type': 'SampleBatch'},\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m   'flow_1.3': { 'data': { 'action_prob': np.ndarray((123,), dtype=float32, min=0.117, max=9.99, mean=2.96),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'actions': np.ndarray((123, 1), dtype=float32, min=-1.722, max=1.788, mean=0.654),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'advantages': np.ndarray((123,), dtype=float32, min=-3.146, max=3.559, mean=-0.049),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'agent_index': np.ndarray((123,), dtype=int64, min=3.0, max=3.0, mean=3.0),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'behaviour_logits': np.ndarray((123, 2), dtype=float32, min=-3.241, max=1.565, mean=-0.779),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'dones': np.ndarray((123,), dtype=bool, min=0.0, max=1.0, mean=0.008),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'eps_id': np.ndarray((123,), dtype=int64, min=248781626.0, max=248781626.0, mean=248781626.0),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'infos': np.ndarray((123,), dtype=object, head={'cost2': 0.0, 'cost1': 0.6117945984235549, 'mean_vel': 16.937247457491157, 'outflow': 915.2542372881356}),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'new_obs': np.ndarray((123, 12), dtype=float32, min=-0.182, max=1.0, mean=0.399),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'obs': np.ndarray((123, 12), dtype=float32, min=-0.182, max=1.0, mean=0.397),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'prev_actions': np.ndarray((123, 1), dtype=float32, min=-1.722, max=1.788, mean=0.642),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'prev_rewards': np.ndarray((123,), dtype=float32, min=-0.428, max=-0.374, mean=-0.399),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'rewards': np.ndarray((123,), dtype=float32, min=-0.428, max=-0.374, mean=-0.399),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           't': np.ndarray((123,), dtype=int64, min=76.0, max=198.0, mean=137.0),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'unroll_id': np.ndarray((123,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'value_targets': np.ndarray((123,), dtype=float32, min=-27.766, max=-0.393, mean=-17.399),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'vf_preds': np.ndarray((123,), dtype=float32, min=-28.879, max=-1.219, mean=-17.35)},\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                 'type': 'SampleBatch'},\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m   'flow_1.4': { 'data': { 'action_prob': np.ndarray((142,), dtype=float32, min=0.013, max=13.559, mean=3.796),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'actions': np.ndarray((142, 1), dtype=float32, min=-1.68, max=1.714, mean=0.647),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'advantages': np.ndarray((142,), dtype=float32, min=-7.85, max=2.257, mean=-1.804),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'agent_index': np.ndarray((142,), dtype=int64, min=4.0, max=4.0, mean=4.0),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'behaviour_logits': np.ndarray((142, 2), dtype=float32, min=-3.656, max=1.605, mean=-0.898),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'dones': np.ndarray((142,), dtype=bool, min=0.0, max=1.0, mean=0.007),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'eps_id': np.ndarray((142,), dtype=int64, min=248781626.0, max=248781626.0, mean=248781626.0),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'infos': np.ndarray((142,), dtype=object, head={'cost2': 0.0, 'cost1': 0.6119056382140078, 'mean_vel': 17.378663746115862, 'outflow': 1115.7024793388427}),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'new_obs': np.ndarray((142, 12), dtype=float32, min=-0.449, max=1.0, mean=0.392),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'obs': np.ndarray((142, 12), dtype=float32, min=-0.449, max=1.0, mean=0.391),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'prev_actions': np.ndarray((142, 1), dtype=float32, min=-1.68, max=1.714, mean=0.637),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'prev_rewards': np.ndarray((142,), dtype=float32, min=-0.54, max=-0.374, mean=-0.457),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'rewards': np.ndarray((142,), dtype=float32, min=-0.54, max=-0.374, mean=-0.458),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           't': np.ndarray((142,), dtype=int64, min=141.0, max=282.0, mean=211.5),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'unroll_id': np.ndarray((142,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'value_targets': np.ndarray((142,), dtype=float32, min=-28.724, max=-0.478, mean=-20.364),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'vf_preds': np.ndarray((142,), dtype=float32, min=-30.981, max=-0.943, mean=-18.559)},\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                 'type': 'SampleBatch'},\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m   'flow_1.5': { 'data': { 'action_prob': np.ndarray((118,), dtype=float32, min=0.016, max=14.47, mean=2.643),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'actions': np.ndarray((118, 1), dtype=float32, min=-1.412, max=2.829, mean=0.577),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'advantages': np.ndarray((118,), dtype=float32, min=-10.232, max=14.845, mean=-0.694),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'agent_index': np.ndarray((118,), dtype=int64, min=5.0, max=5.0, mean=5.0),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'behaviour_logits': np.ndarray((118, 2), dtype=float32, min=-3.645, max=1.756, mean=-0.603),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'dones': np.ndarray((118,), dtype=bool, min=0.0, max=1.0, mean=0.008),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'eps_id': np.ndarray((118,), dtype=int64, min=248781626.0, max=248781626.0, mean=248781626.0),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'infos': np.ndarray((118,), dtype=object, head={'cost2': 0.0, 'cost1': 0.5596131300354958, 'mean_vel': 16.687012126143912, 'outflow': 1404.0}),\n",
      "\u001b[2m\u001b[36m(pid=55553)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55553)\u001b[0m Success.\n",
      "\u001b[2m\u001b[36m(pid=55539)\u001b[0m Success.\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'new_obs': np.ndarray((118, 12), dtype=float32, min=-0.775, max=1.0, mean=0.297),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'obs': np.ndarray((118, 12), dtype=float32, min=-0.775, max=1.0, mean=0.296),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'prev_actions': np.ndarray((118, 1), dtype=float32, min=-1.412, max=2.829, mean=0.572),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'prev_rewards': np.ndarray((118,), dtype=float32, min=-0.555, max=-0.429, mean=-0.51),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'rewards': np.ndarray((118,), dtype=float32, min=-0.555, max=-0.429, mean=-0.51),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           't': np.ndarray((118,), dtype=int64, min=207.0, max=324.0, mean=265.5),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'unroll_id': np.ndarray((118,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'value_targets': np.ndarray((118,), dtype=float32, min=-31.748, max=-0.527, mean=-22.473),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'vf_preds': np.ndarray((118,), dtype=float32, min=-28.358, max=-13.349, mean=-21.779)},\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                 'type': 'SampleBatch'},\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m   'flow_1.6': { 'data': { 'action_prob': np.ndarray((51,), dtype=float32, min=0.056, max=2.928, mean=0.968),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'actions': np.ndarray((51, 1), dtype=float32, min=-2.136, max=2.778, mean=-0.289),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'advantages': np.ndarray((51,), dtype=float32, min=-5.444, max=24.778, mean=4.99),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'agent_index': np.ndarray((51,), dtype=int64, min=6.0, max=6.0, mean=6.0),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'behaviour_logits': np.ndarray((51, 2), dtype=float32, min=-1.993, max=0.805, mean=-0.662),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'dones': np.ndarray((51,), dtype=bool, min=0.0, max=1.0, mean=0.02),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'eps_id': np.ndarray((51,), dtype=int64, min=248781626.0, max=248781626.0, mean=248781626.0),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'infos': np.ndarray((51,), dtype=object, head={'cost2': 0.0, 'cost1': 0.5040749984650609, 'mean_vel': 13.491724184617075, 'outflow': 1512.0}),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'new_obs': np.ndarray((51, 12), dtype=float32, min=-0.775, max=1.0, mean=0.191),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'obs': np.ndarray((51, 12), dtype=float32, min=-0.775, max=1.0, mean=0.194),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'prev_actions': np.ndarray((51, 1), dtype=float32, min=-2.136, max=2.778, mean=-0.308),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'prev_rewards': np.ndarray((51,), dtype=float32, min=-0.555, max=-0.466, mean=-0.507),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'rewards': np.ndarray((51,), dtype=float32, min=-0.555, max=-0.466, mean=-0.508),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           't': np.ndarray((51,), dtype=int64, min=274.0, max=324.0, mean=299.0),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'unroll_id': np.ndarray((51,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'value_targets': np.ndarray((51,), dtype=float32, min=-24.735, max=-0.527, mean=-17.881),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                           'vf_preds': np.ndarray((51,), dtype=float32, min=-30.548, max=-18.747, mean=-22.871)},\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m                 'type': 'SampleBatch'}}\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=55592)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55539)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55573)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55573)\u001b[0m Success.\n",
      "\u001b[2m\u001b[36m(pid=55553)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m Success.\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55565)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55565)\u001b[0m Success.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=55587)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55587)\u001b[0m Success.\n",
      "\u001b[2m\u001b[36m(pid=55573)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55565)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55552)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55552)\u001b[0m Success.\n",
      "\u001b[2m\u001b[36m(pid=55568)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55587)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55555)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55555)\u001b[0m Success.\n",
      "\u001b[2m\u001b[36m(pid=55572)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55572)\u001b[0m Success.\n",
      "\u001b[2m\u001b[36m(pid=55568)\u001b[0m Success.\n",
      "\u001b[2m\u001b[36m(pid=55568)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55589)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55589)\u001b[0m Success.\n",
      "\u001b[2m\u001b[36m(pid=55589)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55552)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55555)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55538)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55538)\u001b[0m Success.\n",
      "\u001b[2m\u001b[36m(pid=55572)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55538)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55556)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55556)\u001b[0m Success.\n",
      "\u001b[2m\u001b[36m(pid=55556)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m 2019-05-27 08:17:21,523\tINFO policy_evaluator.py:474 -- Completed sample batch:\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m { 'data': { 'action_prob': np.ndarray((773,), dtype=float32, min=0.013, max=15.078, mean=2.803),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m             'actions': np.ndarray((773, 1), dtype=float32, min=-2.136, max=2.829, mean=0.637),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m             'advantages': np.ndarray((773,), dtype=float32, min=-10.232, max=24.778, mean=0.687),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m             'agent_index': np.ndarray((773,), dtype=int64, min=0.0, max=6.0, mean=2.846),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m             'behaviour_logits': np.ndarray((773, 2), dtype=float32, min=-3.702, max=1.756, mean=-0.708),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m             'dones': np.ndarray((773,), dtype=bool, min=0.0, max=1.0, mean=0.01),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m             'eps_id': np.ndarray((773,), dtype=int64, min=248781626.0, max=1087605240.0, mean=371403965.433),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m             'infos': np.ndarray((773,), dtype=object, head={'cost2': 0.0, 'cost1': 0.6514673324987896, 'mean_vel': 17.996562297812105, 'outflow': 445.5445544554455}),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m             'new_obs': np.ndarray((773, 12), dtype=float32, min=-0.775, max=1.0, mean=0.362),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m             'obs': np.ndarray((773, 12), dtype=float32, min=-0.775, max=1.0, mean=0.36),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m             'prev_actions': np.ndarray((773, 1), dtype=float32, min=-2.136, max=2.829, mean=0.621),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m             'prev_rewards': np.ndarray((773,), dtype=float32, min=-0.555, max=0.0, mean=-0.408),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m             'rewards': np.ndarray((773,), dtype=float32, min=-0.555, max=-0.29, mean=-0.41),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m             't': np.ndarray((773,), dtype=int64, min=0.0, max=324.0, mean=140.51),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m             'unroll_id': np.ndarray((773,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m             'value_targets': np.ndarray((773,), dtype=float32, min=-31.748, max=-0.294, mean=-17.599),\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m             'vf_preds': np.ndarray((773,), dtype=float32, min=-32.997, max=-0.943, mean=-18.286)},\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m   'type': 'SampleBatch'}\n",
      "\u001b[2m\u001b[36m(pid=55548)\u001b[0m \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15689"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = agent.sample(agent.train_batch_size)\n",
    "samples.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-27 08:17:27,706\tINFO json_writer.py:97 -- Writing to new output file <_io.TextIOWrapper name='/headless/rl_project/flow_codes/ModelBased/expert_sample/output-2019-05-27_08-17-27_worker-0_0.json' mode='w' encoding='UTF-8'>\n"
     ]
    }
   ],
   "source": [
    "writer.write(sample_batch=samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.50089616, 0.09269742, 0.17006099, 0.03464941, 0.08645405,\n",
       "       0.3768997 , 0.83368564, 0.46684912, 0.60568887, 0.4934346 ,\n",
       "       0.49899188, 0.09164798], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.calculate_expected_feature(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = JsonReader(\"./expert_sample\")\n",
    "sample = reader.next()\n",
    "sample.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader.next().count"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "varInspector": {
   "cols": {
    "lenName": "50",
    "lenType": "50",
    "lenVar": "50"
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
