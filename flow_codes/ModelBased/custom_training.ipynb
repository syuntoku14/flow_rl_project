{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "* find the varid horizon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym, pickle, argparse, json, logging\n",
    "from itertools import product\n",
    "from copy import deepcopy\n",
    "import tensorflow as tf\n",
    "import ray\n",
    "\n",
    "from ray import tune\n",
    "from ray.rllib.agents.ppo.ppo_policy_graph import PPOPolicyGraph\n",
    "from ray.rllib.agents.ppo.ppo import DEFAULT_CONFIG\n",
    "from ray.rllib.agents import Trainer\n",
    "from ray.rllib.evaluation import PolicyEvaluator, SampleBatch\n",
    "from ray.rllib.evaluation.metrics import collect_metrics\n",
    "from ray.tune.registry import register_env\n",
    "from ray.rllib.optimizers.rollout import collect_samples\n",
    "from ray.rllib.utils.annotations import override\n",
    "\n",
    "from flow.multiagent_envs import MultiWaveAttenuationPOEnv\n",
    "from flow.utils.registry import make_create_env\n",
    "from flow.utils.rllib import FlowParamsEncoder, get_flow_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_cpus = 3\n",
    "num_rollouts = 3\n",
    "horizon = 750\n",
    "gae_lambda = 0.97\n",
    "step_size = 5e-4\n",
    "num_iter = 10\n",
    "benchmark_name = \"multi_merge\"\n",
    "exp_name = \"test_ir\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '169.237.32.118',\n",
       " 'object_store_address': '/tmp/ray/session_2019-05-25_09-04-36_12576/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2019-05-25_09-04-36_12576/sockets/raylet',\n",
       " 'redis_address': '169.237.32.118:50356',\n",
       " 'webui_url': None}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init(num_cpus=num_cpus, logging_level=40, ignore_reinit_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = deepcopy(DEFAULT_CONFIG)\n",
    "config[\"num_workers\"] = min(num_cpus, num_rollouts)\n",
    "config[\"train_batch_size\"] = horizon * num_rollouts\n",
    "config[\"sample_batch_size\"] = horizon / 2\n",
    "config[\"use_gae\"] = True\n",
    "config[\"horizon\"] = horizon\n",
    "config[\"lambda\"] = gae_lambda\n",
    "config[\"lr\"] = step_size\n",
    "config[\"vf_clip_param\"] = 1e6\n",
    "config[\"num_sgd_iter\"] = 10\n",
    "config['clip_actions'] = False  # FIXME(ev) temporary ray bug\n",
    "config[\"model\"][\"fcnet_hiddens\"] = [128, 64, 32]\n",
    "config[\"observation_filter\"] = \"NoFilter\"\n",
    "config[\"entropy_coeff\"] = 0.0\n",
    "\n",
    "benchmark = __import__(\n",
    "            \"flow.benchmarks.%s\" % benchmark_name, fromlist=[\"flow_params\"])\n",
    "flow_params = benchmark.buffered_obs_flow_params\n",
    "\n",
    "# save the flow params for replay\n",
    "flow_json = json.dumps(\n",
    "    flow_params, cls=FlowParamsEncoder, sort_keys=True, indent=4)\n",
    "config['env_config']['flow_params'] = flow_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_env, env_name = make_create_env(params=flow_params, version=0)\n",
    "register_env(env_name, create_env)\n",
    "env = create_env()\n",
    "\n",
    "default_policy = (PPOPolicyGraph, env.observation_space, env.action_space, {})\n",
    "policy_graph = {\"default_policy\": default_policy}\n",
    "config[\"multiagent\"] = {\n",
    "        'policy_graphs': policy_graph,\n",
    "        'policy_mapping_fn': tune.function(lambda agent_id: \"default_policy\")\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GailTrainer(Trainer):\n",
    "    _name = \"GAIL\"\n",
    "    _default_config = DEFAULT_CONFIG\n",
    "    _policy_graph = PPOPolicyGraph\n",
    "    \n",
    "    @override(Trainer)\n",
    "    def _init(self, config, env_creator):\n",
    "        self.local_evaluator = self.make_local_evaluator(\n",
    "             env_creator, self._policy_graph)        \n",
    "        self.remote_evaluators = self.make_remote_evaluators(\n",
    "            env_creator, self._policy_graph, config[\"num_workers\"])\n",
    "        \n",
    "        self.sample_batch_size = config[\"sample_batch_size\"]\n",
    "        self.num_envs_per_worker = config[\"num_envs_per_worker\"]\n",
    "        self.train_batch_size = config[\"train_batch_size\"]\n",
    "        self.num_sgd_iter = config[\"num_sgd_iter\"]\n",
    "        self.sgd_minibatch_size = config[\"sgd_minibatch_size\"]\n",
    "        \n",
    "    @override(Trainer)    \n",
    "    def _train(self):\n",
    "        weights = ray.put(self.local_evaluator.get_weights())\n",
    "        for e in self.remote_evaluators:\n",
    "            e.set_weights.remote(weights)       \n",
    "        \n",
    "        # collect samples\n",
    "        samples = collect_samples(\n",
    "            self.remote_evaluators, self.sample_batch_size,\n",
    "            self.num_envs_per_worker, self.train_batch_size)\n",
    "        \n",
    "        samples.shuffle()\n",
    "        \n",
    "        print(\"sample finished\")\n",
    "        # training\n",
    "        for _ in range(self.num_sgd_iter):\n",
    "            for i in range(0, samples.count, self.sgd_minibatch_size):\n",
    "                minibatch = samples.slice(i, i+self.sgd_minibatch_size)\n",
    "                self.local_evaluator.learn_on_batch(minibatch)\n",
    "        return collect_metrics(remote_evaluators=self.remote_evaluators)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-25 09:05:53,064\tINFO policy_evaluator.py:311 -- Creating policy evaluation worker 0 on CPU (please ignore any CUDA init errors)\n",
      "/opt/conda/envs/flow-latest/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "2019-05-25 09:05:54,471\tINFO policy_evaluator.py:728 -- Built policy map: {'default_policy': <ray.rllib.agents.ppo.ppo_policy_graph.PPOPolicyGraph object at 0x7f562d0bbb00>}\n",
      "2019-05-25 09:05:54,472\tINFO policy_evaluator.py:729 -- Built preprocessor map: {'default_policy': <ray.rllib.models.preprocessors.NoPreprocessor object at 0x7f562d0bb7f0>}\n",
      "2019-05-25 09:05:54,473\tINFO policy_evaluator.py:343 -- Built filter map: {'default_policy': <ray.rllib.utils.filter.NoFilter object at 0x7f562e153080>}\n"
     ]
    }
   ],
   "source": [
    "agent = GailTrainer(config, env_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12613)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=12613)\u001b[0m Success.\n",
      "\u001b[2m\u001b[36m(pid=12616)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=12616)\u001b[0m Success.\n",
      "\u001b[2m\u001b[36m(pid=12613)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=12616)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m Success.\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=12613)\u001b[0m 2019-05-25 09:06:05,738\tINFO policy_evaluator.py:311 -- Creating policy evaluation worker 2 on CPU (please ignore any CUDA init errors)\n",
      "\u001b[2m\u001b[36m(pid=12613)\u001b[0m 2019-05-25 09:06:05.740473: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "\u001b[2m\u001b[36m(pid=12616)\u001b[0m 2019-05-25 09:06:05,787\tINFO policy_evaluator.py:311 -- Creating policy evaluation worker 3 on CPU (please ignore any CUDA init errors)\n",
      "\u001b[2m\u001b[36m(pid=12616)\u001b[0m 2019-05-25 09:06:05.789457: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m 2019-05-25 09:06:05,864\tINFO policy_evaluator.py:311 -- Creating policy evaluation worker 1 on CPU (please ignore any CUDA init errors)\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m 2019-05-25 09:06:05.866700: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "\u001b[2m\u001b[36m(pid=12616)\u001b[0m /opt/conda/envs/flow-latest/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "\u001b[2m\u001b[36m(pid=12616)\u001b[0m   \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "\u001b[2m\u001b[36m(pid=12613)\u001b[0m /opt/conda/envs/flow-latest/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "\u001b[2m\u001b[36m(pid=12613)\u001b[0m   \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m /opt/conda/envs/flow-latest/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m   \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "\u001b[2m\u001b[36m(pid=12613)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=12613)\u001b[0m Success.\n",
      "\u001b[2m\u001b[36m(pid=12616)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=12616)\u001b[0m Success.\n",
      "\u001b[2m\u001b[36m(pid=12613)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=12616)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m 2019-05-25 09:06:07,195\tINFO policy_evaluator.py:437 -- Generating sample batch of size 375.0\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m Success.\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m 2019-05-25 09:06:08,674\tINFO sampler.py:308 -- Raw obs from env: { 0: { 'flow_1.0': np.ndarray((12,), dtype=float32, min=0.0, max=1.0, mean=0.508),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m        'flow_1.1': np.ndarray((12,), dtype=float32, min=0.016, max=0.841, mean=0.193)}}\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m 2019-05-25 09:06:08,674\tINFO sampler.py:309 -- Info return from env: {0: {'flow_1.0': {}, 'flow_1.1': {}}}\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m 2019-05-25 09:06:08,675\tINFO sampler.py:407 -- Preprocessed obs: np.ndarray((12,), dtype=float32, min=0.0, max=1.0, mean=0.508)\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m 2019-05-25 09:06:08,675\tINFO sampler.py:411 -- Filtered obs: np.ndarray((12,), dtype=float32, min=0.0, max=1.0, mean=0.508)\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m 2019-05-25 09:06:08,676\tINFO sampler.py:525 -- Inputs to compute_actions():\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m { 'default_policy': [ { 'data': { 'agent_id': 'flow_1.0',\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                                   'env_id': 0,\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                                   'info': {},\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                                   'obs': np.ndarray((12,), dtype=float32, min=0.0, max=1.0, mean=0.508),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                                   'prev_action': np.ndarray((1,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                                   'prev_reward': 0.0,\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                                   'rnn_state': []},\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                         'type': 'PolicyEvalData'},\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                       { 'data': { 'agent_id': 'flow_1.1',\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                                   'env_id': 0,\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                                   'info': {},\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                                   'obs': np.ndarray((12,), dtype=float32, min=0.016, max=0.841, mean=0.193),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                                   'prev_action': np.ndarray((1,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                                   'prev_reward': 0.0,\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                                   'rnn_state': []},\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                         'type': 'PolicyEvalData'}]}\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m 2019-05-25 09:06:08,677\tINFO tf_run_builder.py:89 -- Executing TF run without tracing. To dump TF timeline traces to disk, set the TF_TIMELINE_DIR environment variable.\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m 2019-05-25 09:06:08,715\tINFO sampler.py:552 -- Outputs of compute_actions():\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m { 'default_policy': ( np.ndarray((2, 1), dtype=float32, min=-2.162, max=-0.1, mean=-1.131),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                       [],\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                       { 'action_prob': np.ndarray((2,), dtype=float32, min=0.039, max=0.397, mean=0.218),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                         'behaviour_logits': np.ndarray((2, 2), dtype=float32, min=-0.003, max=0.004, mean=0.001),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                         'vf_preds': np.ndarray((2,), dtype=float32, min=0.004, max=0.01, mean=0.007)})}\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=12616)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=12616)\u001b[0m Success.\n",
      "\u001b[2m\u001b[36m(pid=12616)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=12613)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=12613)\u001b[0m Success.\n",
      "\u001b[2m\u001b[36m(pid=12613)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m 2019-05-25 09:06:12,034\tINFO sample_batch_builder.py:161 -- Trajectory fragment after postprocess_trajectory():\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m { 'flow_1.0': { 'data': { 'action_prob': np.ndarray((26,), dtype=float32, min=0.013, max=0.398, mean=0.272),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'actions': np.ndarray((26, 1), dtype=float32, min=-2.624, max=1.9, mean=0.029),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'advantages': np.ndarray((26,), dtype=float32, min=-5.003, max=-0.322, mean=-3.004),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'agent_index': np.ndarray((26,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'behaviour_logits': np.ndarray((26, 2), dtype=float32, min=-0.003, max=0.004, mean=0.001),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'dones': np.ndarray((26,), dtype=bool, min=0.0, max=1.0, mean=0.038),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'eps_id': np.ndarray((26,), dtype=int64, min=1973462552.0, max=1973462552.0, mean=1973462552.0),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'infos': np.ndarray((26,), dtype=object, head={'cost2': 0.0, 'mean_vel': 18.42277912546916, 'cost1': 0.656321021655528, 'outflow': 445.5445544554455}),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'new_obs': np.ndarray((26, 12), dtype=float32, min=-0.04, max=1.0, mean=0.531),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'obs': np.ndarray((26, 12), dtype=float32, min=-0.04, max=1.0, mean=0.528),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'prev_actions': np.ndarray((26, 1), dtype=float32, min=-2.624, max=1.9, mean=0.028),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'prev_rewards': np.ndarray((26,), dtype=float32, min=-0.321, max=0.0, mean=-0.292),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'rewards': np.ndarray((26,), dtype=float32, min=-0.321, max=-0.291, mean=-0.304),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           't': np.ndarray((26,), dtype=int64, min=0.0, max=25.0, mean=12.5),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'unroll_id': np.ndarray((26,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'value_targets': np.ndarray((26,), dtype=float32, min=-4.993, max=-0.31, mean=-2.994),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'vf_preds': np.ndarray((26,), dtype=float32, min=0.009, max=0.012, mean=0.01)},\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                 'type': 'SampleBatch'},\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m   'flow_1.1': { 'data': { 'action_prob': np.ndarray((109,), dtype=float32, min=0.002, max=0.398, mean=0.282),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'actions': np.ndarray((109, 1), dtype=float32, min=-2.229, max=3.312, mean=0.078),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'advantages': np.ndarray((109,), dtype=float32, min=-11.66, max=-0.613, mean=-9.272),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'agent_index': np.ndarray((109,), dtype=int64, min=1.0, max=1.0, mean=1.0),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'behaviour_logits': np.ndarray((109, 2), dtype=float32, min=-0.003, max=0.004, mean=0.001),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'dones': np.ndarray((109,), dtype=bool, min=0.0, max=1.0, mean=0.009),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'eps_id': np.ndarray((109,), dtype=int64, min=1973462552.0, max=1973462552.0, mean=1973462552.0),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'infos': np.ndarray((109,), dtype=object, head={'cost2': 0.0, 'mean_vel': 18.42277912546916, 'cost1': 0.656321021655528, 'outflow': 445.5445544554455}),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'new_obs': np.ndarray((109, 12), dtype=float32, min=-0.04, max=1.0, mean=0.471),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'obs': np.ndarray((109, 12), dtype=float32, min=-0.04, max=1.0, mean=0.467),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'prev_actions': np.ndarray((109, 1), dtype=float32, min=-2.229, max=3.312, mean=0.083),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'prev_rewards': np.ndarray((109,), dtype=float32, min=-0.602, max=0.0, mean=-0.437),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'rewards': np.ndarray((109,), dtype=float32, min=-0.602, max=-0.291, mean=-0.442),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           't': np.ndarray((109,), dtype=int64, min=0.0, max=108.0, mean=54.0),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'unroll_id': np.ndarray((109,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'value_targets': np.ndarray((109,), dtype=float32, min=-11.65, max=-0.602, mean=-9.262),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'vf_preds': np.ndarray((109,), dtype=float32, min=0.004, max=0.011, mean=0.009)},\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                 'type': 'SampleBatch'},\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m   'flow_1.2': { 'data': { 'action_prob': np.ndarray((310,), dtype=float32, min=0.002, max=0.399, mean=0.289),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'actions': np.ndarray((310, 1), dtype=float32, min=-3.269, max=3.087, mean=0.007),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'advantages': np.ndarray((310,), dtype=float32, min=-21.889, max=-0.947, mean=-17.179),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'agent_index': np.ndarray((310,), dtype=int64, min=2.0, max=2.0, mean=2.0),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'behaviour_logits': np.ndarray((310, 2), dtype=float32, min=-0.003, max=0.005, mean=0.001),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'dones': np.ndarray((310,), dtype=bool, min=0.0, max=1.0, mean=0.003),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'eps_id': np.ndarray((310,), dtype=int64, min=1973462552.0, max=1973462552.0, mean=1973462552.0),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'infos': np.ndarray((310,), dtype=object, head={'cost2': 0.0, 'mean_vel': 18.524139804742287, 'cost1': 0.6732868716158597, 'outflow': 465.5172413793103}),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'new_obs': np.ndarray((310, 12), dtype=float32, min=-0.156, max=1.0, mean=0.467),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'obs': np.ndarray((310, 12), dtype=float32, min=-0.156, max=1.0, mean=0.466),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'prev_actions': np.ndarray((310, 1), dtype=float32, min=-3.269, max=3.087, mean=0.008),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'prev_rewards': np.ndarray((310,), dtype=float32, min=-0.933, max=-0.291, mean=-0.709),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'rewards': np.ndarray((310,), dtype=float32, min=-0.936, max=-0.291, mean=-0.711),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           't': np.ndarray((310,), dtype=int64, min=15.0, max=324.0, mean=169.5),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'unroll_id': np.ndarray((310,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'value_targets': np.ndarray((310,), dtype=float32, min=-21.88, max=-0.936, mean=-17.17),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'vf_preds': np.ndarray((310,), dtype=float32, min=-0.002, max=0.011, mean=0.009)},\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                 'type': 'SampleBatch'},\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m   'flow_1.3': { 'data': { 'action_prob': np.ndarray((256,), dtype=float32, min=0.009, max=0.399, mean=0.276),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'actions': np.ndarray((256, 1), dtype=float32, min=-2.778, max=2.107, mean=-0.054),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'advantages': np.ndarray((256,), dtype=float32, min=-21.886, max=-0.944, mean=-18.256),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'agent_index': np.ndarray((256,), dtype=int64, min=3.0, max=3.0, mean=3.0),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'behaviour_logits': np.ndarray((256, 2), dtype=float32, min=-0.003, max=0.003, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'dones': np.ndarray((256,), dtype=bool, min=0.0, max=1.0, mean=0.004),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'eps_id': np.ndarray((256,), dtype=int64, min=1973462552.0, max=1973462552.0, mean=1973462552.0),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'infos': np.ndarray((256,), dtype=object, head={'cost2': 0.0, 'mean_vel': 11.6424029230852, 'cost1': 0.4371453316065731, 'outflow': 900.0}),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'new_obs': np.ndarray((256, 12), dtype=float32, min=-0.156, max=1.0, mean=0.198),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'obs': np.ndarray((256, 12), dtype=float32, min=-0.156, max=1.0, mean=0.199),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'prev_actions': np.ndarray((256, 1), dtype=float32, min=-2.778, max=2.107, mean=-0.049),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'prev_rewards': np.ndarray((256,), dtype=float32, min=-0.933, max=-0.517, mean=-0.778),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'rewards': np.ndarray((256,), dtype=float32, min=-0.936, max=-0.518, mean=-0.779),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           't': np.ndarray((256,), dtype=int64, min=69.0, max=324.0, mean=196.5),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'unroll_id': np.ndarray((256,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'value_targets': np.ndarray((256,), dtype=float32, min=-21.882, max=-0.936, mean=-18.251),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'vf_preds': np.ndarray((256,), dtype=float32, min=-0.001, max=0.007, mean=0.005)},\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                 'type': 'SampleBatch'},\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m   'flow_1.4': { 'data': { 'action_prob': np.ndarray((184,), dtype=float32, min=0.007, max=0.399, mean=0.283),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'actions': np.ndarray((184, 1), dtype=float32, min=-2.841, max=2.435, mean=-0.043),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'advantages': np.ndarray((184,), dtype=float32, min=-21.887, max=-0.938, mean=-18.885),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'agent_index': np.ndarray((184,), dtype=int64, min=4.0, max=4.0, mean=4.0),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'behaviour_logits': np.ndarray((184, 2), dtype=float32, min=-0.003, max=0.004, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'dones': np.ndarray((184,), dtype=bool, min=0.0, max=1.0, mean=0.005),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'eps_id': np.ndarray((184,), dtype=int64, min=1973462552.0, max=1973462552.0, mean=1973462552.0),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'infos': np.ndarray((184,), dtype=object, head={'cost2': 0.0, 'mean_vel': 6.825544543766932, 'cost1': 0.2661116259848213, 'outflow': 1004.1322314049586}),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'new_obs': np.ndarray((184, 12), dtype=float32, min=-0.113, max=1.0, mean=0.113),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'obs': np.ndarray((184, 12), dtype=float32, min=-0.113, max=1.0, mean=0.114),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'prev_actions': np.ndarray((184, 1), dtype=float32, min=-2.841, max=2.435, mean=-0.034),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'prev_rewards': np.ndarray((184,), dtype=float32, min=-0.933, max=-0.671, mean=-0.847),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'rewards': np.ndarray((184,), dtype=float32, min=-0.936, max=-0.684, mean=-0.849),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           't': np.ndarray((184,), dtype=int64, min=141.0, max=324.0, mean=232.5),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'unroll_id': np.ndarray((184,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'value_targets': np.ndarray((184,), dtype=float32, min=-21.887, max=-0.936, mean=-18.884),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                           'vf_preds': np.ndarray((184,), dtype=float32, min=-0.003, max=0.009, mean=0.001)},\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m                 'type': 'SampleBatch'}}\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m Success.\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m Loading configuration... done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m 2019-05-25 09:06:13,975\tINFO policy_evaluator.py:474 -- Completed sample batch:\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m { 'data': { 'action_prob': np.ndarray((999,), dtype=float32, min=0.002, max=0.399, mean=0.283),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m             'actions': np.ndarray((999, 1), dtype=float32, min=-3.269, max=3.312, mean=0.003),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m             'advantages': np.ndarray((999,), dtype=float32, min=-21.889, max=-0.322, mean=-15.139),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m             'agent_index': np.ndarray((999,), dtype=int64, min=0.0, max=4.0, mean=2.355),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m             'behaviour_logits': np.ndarray((999, 2), dtype=float32, min=-0.003, max=0.005, mean=0.001),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m             'dones': np.ndarray((999,), dtype=bool, min=0.0, max=1.0, mean=0.006),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m             'eps_id': np.ndarray((999,), dtype=int64, min=847589202.0, max=1973462552.0, mean=1844984512.06),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m             'infos': np.ndarray((999,), dtype=object, head={'cost2': 0.0, 'mean_vel': 18.42277912546916, 'cost1': 0.656321021655528, 'outflow': 445.5445544554455}),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m             'new_obs': np.ndarray((999, 12), dtype=float32, min=-0.156, max=1.0, mean=0.322),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m             'obs': np.ndarray((999, 12), dtype=float32, min=-0.156, max=1.0, mean=0.321),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m             'prev_actions': np.ndarray((999, 1), dtype=float32, min=-3.269, max=3.312, mean=0.007),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m             'prev_rewards': np.ndarray((999,), dtype=float32, min=-0.933, max=0.0, mean=-0.671),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m             'rewards': np.ndarray((999,), dtype=float32, min=-0.936, max=-0.286, mean=-0.674),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m             't': np.ndarray((999,), dtype=int64, min=0.0, max=324.0, mean=154.746),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m             'unroll_id': np.ndarray((999,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m             'value_targets': np.ndarray((999,), dtype=float32, min=-21.887, max=-0.31, mean=-15.133),\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m             'vf_preds': np.ndarray((999,), dtype=float32, min=-0.003, max=0.012, mean=0.006)},\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m   'type': 'SampleBatch'}\n",
      "\u001b[2m\u001b[36m(pid=12615)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=12616)\u001b[0m Loading configuration... done.\n",
      "\u001b[2m\u001b[36m(pid=12616)\u001b[0m Success.\n",
      "\u001b[2m\u001b[36m(pid=12616)\u001b[0m Loading configuration... done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-25 09:06:18,538\tINFO policy_evaluator.py:564 -- Training on concatenated sample batches:\n",
      "\n",
      "{ 'data': { 'action_prob': np.ndarray((128,), dtype=float32, min=0.011, max=0.399, mean=0.287),\n",
      "            'actions': np.ndarray((128, 1), dtype=float32, min=-2.356, max=2.692, mean=0.157),\n",
      "            'advantages': np.ndarray((128,), dtype=float32, min=-22.787, max=-0.587, mean=-15.674),\n",
      "            'agent_index': np.ndarray((128,), dtype=int64, min=0.0, max=4.0, mean=2.367),\n",
      "            'behaviour_logits': np.ndarray((128, 2), dtype=float32, min=-0.004, max=0.004, mean=0.001),\n",
      "            'dones': np.ndarray((128,), dtype=bool, min=0.0, max=1.0, mean=0.008),\n",
      "            'eps_id': np.ndarray((128,), dtype=int64, min=499316056.0, max=1973462552.0, mean=1221446586.5),\n",
      "            'infos': np.ndarray((128,), dtype=object, head={'outflow': 634.6153846153845, 'mean_vel': 9.988621121364885, 'cost1': 0.3819637238971747, 'cost2': 0.0}),\n",
      "            'new_obs': np.ndarray((128, 12), dtype=float32, min=-0.215, max=1.0, mean=0.312),\n",
      "            'obs': np.ndarray((128, 12), dtype=float32, min=-0.206, max=1.0, mean=0.314),\n",
      "            'prev_actions': np.ndarray((128, 1), dtype=float32, min=-3.481, max=2.463, mean=-0.154),\n",
      "            'prev_rewards': np.ndarray((128,), dtype=float32, min=-0.95, max=-0.288, mean=-0.689),\n",
      "            'rewards': np.ndarray((128,), dtype=float32, min=-0.95, max=-0.288, mean=-0.69),\n",
      "            't': np.ndarray((128,), dtype=int64, min=2.0, max=324.0, mean=152.32),\n",
      "            'unroll_id': np.ndarray((128,), dtype=int64, min=0.0, max=1.0, mean=0.312),\n",
      "            'value_targets': np.ndarray((128,), dtype=float32, min=-22.778, max=-0.575, mean=-15.668),\n",
      "            'vf_preds': np.ndarray((128,), dtype=float32, min=-0.003, max=0.012, mean=0.006)},\n",
      "  'type': 'SampleBatch'}\n",
      "\n",
      "2019-05-25 09:06:18,539\tINFO tf_run_builder.py:89 -- Executing TF run without tracing. To dump TF timeline traces to disk, set the TF_TIMELINE_DIR environment variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-25 09:06:18,898\tINFO policy_evaluator.py:586 -- Training output:\n",
      "\n",
      "{ 'learner_stats': { 'cur_kl_coeff': 0.2,\n",
      "                     'cur_lr': 0.0005000000237487257,\n",
      "                     'entropy': 1.419771,\n",
      "                     'kl': 0.0,\n",
      "                     'model': {},\n",
      "                     'policy_loss': 15.674466,\n",
      "                     'total_loss': 305.69653,\n",
      "                     'vf_explained_var': 0.00040441751,\n",
      "                     'vf_loss': 290.0221}}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'custom_metrics': {},\n",
       " 'episode_len_mean': 325.0,\n",
       " 'episode_reward_max': -435.3691063038351,\n",
       " 'episode_reward_mean': -590.9078521917835,\n",
       " 'episode_reward_min': -662.9207913183753,\n",
       " 'episodes_this_iter': 4,\n",
       " 'num_metric_batches_dropped': 0,\n",
       " 'off_policy_estimator': {},\n",
       " 'policy_reward_mean': {},\n",
       " 'sampler_perf': {'mean_env_wait_ms': 11.232646075107828,\n",
       "  'mean_inference_ms': 0.9979232888193101,\n",
       "  'mean_processing_ms': 4.376337145797848}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent._train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 1.7/33.4 GB\n",
      "\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 1.7/33.4 GB\n",
      "Result logdir: /headless/ray_results/test_ir\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - GailTrainer_MultiWaveAttenuationMergePOEnvBufferedObs-v0_0:\tRUNNING\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-25 06:36:55,542\tERROR trial_runner.py:494 -- Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/site-packages/ray/tune/trial_runner.py\", line 443, in _process_trial\n",
      "    result = self.trial_executor.fetch_result(trial)\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/site-packages/ray/tune/ray_trial_executor.py\", line 315, in fetch_result\n",
      "    result = ray.get(trial_future[0])\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/site-packages/ray/worker.py\", line 2193, in get\n",
      "    raise value\n",
      "ray.exceptions.RayTaskError: \u001b[36mray_GailTrainer:train()\u001b[39m (pid=8953, host=kronos)\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/site-packages/ray/rllib/agents/trainer.py\", line 293, in __init__\n",
      "    Trainable.__init__(self, config, logger_creator)\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/site-packages/ray/tune/trainable.py\", line 88, in __init__\n",
      "    self._setup(copy.deepcopy(self.config))\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/site-packages/ray/rllib/agents/trainer.py\", line 393, in _setup\n",
      "    self._init(self.config, self.env_creator)\n",
      "  File \"<ipython-input-6-9b2a9ceb16ab>\", line 9, in _init\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 5303, in reset_default_graph\n",
      "    raise AssertionError(\"Do not use tf.reset_default_graph() to clear \"\n",
      "AssertionError: Do not use tf.reset_default_graph() to clear nested graphs. If you need a cleared graph, exit the nesting and create a new graph.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 1.9/33.4 GB\n",
      "Result logdir: /headless/ray_results/test_ir\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - GailTrainer_MultiWaveAttenuationMergePOEnvBufferedObs-v0_0:\tRUNNING, 1 failures: /headless/ray_results/test_ir/GailTrainer_MultiWaveAttenuationMergePOEnvBufferedObs-v0_0_2019-05-25_06-36-45y51s7ud9/error_2019-05-25_06-36-55.txt\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-25 06:37:05,623\tERROR trial_runner.py:494 -- Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/site-packages/ray/tune/trial_runner.py\", line 443, in _process_trial\n",
      "    result = self.trial_executor.fetch_result(trial)\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/site-packages/ray/tune/ray_trial_executor.py\", line 315, in fetch_result\n",
      "    result = ray.get(trial_future[0])\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/site-packages/ray/worker.py\", line 2193, in get\n",
      "    raise value\n",
      "ray.exceptions.RayTaskError: \u001b[36mray_GailTrainer:train()\u001b[39m (pid=8952, host=kronos)\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/site-packages/ray/rllib/agents/trainer.py\", line 293, in __init__\n",
      "    Trainable.__init__(self, config, logger_creator)\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/site-packages/ray/tune/trainable.py\", line 88, in __init__\n",
      "    self._setup(copy.deepcopy(self.config))\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/site-packages/ray/rllib/agents/trainer.py\", line 393, in _setup\n",
      "    self._init(self.config, self.env_creator)\n",
      "  File \"<ipython-input-6-9b2a9ceb16ab>\", line 9, in _init\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 5303, in reset_default_graph\n",
      "    raise AssertionError(\"Do not use tf.reset_default_graph() to clear \"\n",
      "AssertionError: Do not use tf.reset_default_graph() to clear nested graphs. If you need a cleared graph, exit the nesting and create a new graph.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 1.9/33.4 GB\n",
      "Result logdir: /headless/ray_results/test_ir\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - GailTrainer_MultiWaveAttenuationMergePOEnvBufferedObs-v0_0:\tRUNNING, 2 failures: /headless/ray_results/test_ir/GailTrainer_MultiWaveAttenuationMergePOEnvBufferedObs-v0_0_2019-05-25_06-36-45y51s7ud9/error_2019-05-25_06-37-05.txt\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-25 06:37:15,741\tERROR trial_runner.py:494 -- Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/site-packages/ray/tune/trial_runner.py\", line 443, in _process_trial\n",
      "    result = self.trial_executor.fetch_result(trial)\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/site-packages/ray/tune/ray_trial_executor.py\", line 315, in fetch_result\n",
      "    result = ray.get(trial_future[0])\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/site-packages/ray/worker.py\", line 2193, in get\n",
      "    raise value\n",
      "ray.exceptions.RayTaskError: \u001b[36mray_GailTrainer:train()\u001b[39m (pid=8949, host=kronos)\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/site-packages/ray/rllib/agents/trainer.py\", line 293, in __init__\n",
      "    Trainable.__init__(self, config, logger_creator)\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/site-packages/ray/tune/trainable.py\", line 88, in __init__\n",
      "    self._setup(copy.deepcopy(self.config))\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/site-packages/ray/rllib/agents/trainer.py\", line 393, in _setup\n",
      "    self._init(self.config, self.env_creator)\n",
      "  File \"<ipython-input-6-9b2a9ceb16ab>\", line 9, in _init\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 5303, in reset_default_graph\n",
      "    raise AssertionError(\"Do not use tf.reset_default_graph() to clear \"\n",
      "AssertionError: Do not use tf.reset_default_graph() to clear nested graphs. If you need a cleared graph, exit the nesting and create a new graph.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 1.9/33.4 GB\n",
      "Result logdir: /headless/ray_results/test_ir\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - GailTrainer_MultiWaveAttenuationMergePOEnvBufferedObs-v0_0:\tRUNNING, 3 failures: /headless/ray_results/test_ir/GailTrainer_MultiWaveAttenuationMergePOEnvBufferedObs-v0_0_2019-05-25_06-36-45y51s7ud9/error_2019-05-25_06-37-15.txt\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread ray_print_logs:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/site-packages/redis/connection.py\", line 177, in _read_from_socket\n",
      "    raise socket.error(SERVER_CLOSED_CONNECTION_ERROR)\n",
      "OSError: Connection closed by server.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/site-packages/redis/client.py\", line 2408, in _execute\n",
      "    return command(*args)\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/site-packages/redis/connection.py\", line 624, in read_response\n",
      "    response = self._parser.read_response()\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/site-packages/redis/connection.py\", line 284, in read_response\n",
      "    response = self._buffer.readline()\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/site-packages/redis/connection.py\", line 216, in readline\n",
      "    self._read_from_socket()\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/site-packages/redis/connection.py\", line 191, in _read_from_socket\n",
      "    (e.args,))\n",
      "redis.exceptions.ConnectionError: Error while reading from socket: ('Connection closed by server.',)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/site-packages/redis/connection.py\", line 484, in connect\n",
      "    sock = self._connect()\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/site-packages/redis/connection.py\", line 541, in _connect\n",
      "    raise err\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/site-packages/redis/connection.py\", line 529, in _connect\n",
      "    sock.connect(socket_address)\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/threading.py\", line 914, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/threading.py\", line 862, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/site-packages/ray/worker.py\", line 1547, in print_logs\n",
      "    msg = pubsub_client.get_message()\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/site-packages/redis/client.py\", line 2513, in get_message\n",
      "    response = self.parse_response(block=False, timeout=timeout)\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/site-packages/redis/client.py\", line 2430, in parse_response\n",
      "    return self._execute(connection, connection.read_response)\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/site-packages/redis/client.py\", line 2415, in _execute\n",
      "    connection.connect()\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/site-packages/redis/connection.py\", line 489, in connect\n",
      "    raise ConnectionError(self._error_message(e))\n",
      "redis.exceptions.ConnectionError: Error 111 connecting to 169.237.32.118:33623. Connection refused.\n",
      "\n",
      "Exception in thread ray_listen_error_messages:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/site-packages/redis/connection.py\", line 177, in _read_from_socket\n",
      "    raise socket.error(SERVER_CLOSED_CONNECTION_ERROR)\n",
      "OSError: Connection closed by server.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/site-packages/redis/client.py\", line 2408, in _execute\n",
      "    return command(*args)\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/site-packages/redis/connection.py\", line 624, in read_response\n",
      "    response = self._parser.read_response()\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/site-packages/redis/connection.py\", line 284, in read_response\n",
      "    response = self._buffer.readline()\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/site-packages/redis/connection.py\", line 216, in readline\n",
      "    self._read_from_socket()\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/site-packages/redis/connection.py\", line 191, in _read_from_socket\n",
      "    (e.args,))\n",
      "redis.exceptions.ConnectionError: Error while reading from socket: ('Connection closed by server.',)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/site-packages/redis/connection.py\", line 484, in connect\n",
      "    sock = self._connect()\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/site-packages/redis/connection.py\", line 541, in _connect\n",
      "    raise err\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/site-packages/redis/connection.py\", line 529, in _connect\n",
      "    sock.connect(socket_address)\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/threading.py\", line 914, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/threading.py\", line 862, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/site-packages/ray/worker.py\", line 1650, in listen_error_messages_raylet\n",
      "    msg = worker.error_message_pubsub_client.get_message()\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/site-packages/redis/client.py\", line 2513, in get_message\n",
      "    response = self.parse_response(block=False, timeout=timeout)\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/site-packages/redis/client.py\", line 2430, in parse_response\n",
      "    return self._execute(connection, connection.read_response)\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/site-packages/redis/client.py\", line 2415, in _execute\n",
      "    connection.connect()\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/site-packages/redis/connection.py\", line 489, in connect\n",
      "    raise ConnectionError(self._error_message(e))\n",
      "redis.exceptions.ConnectionError: Error 111 connecting to 169.237.32.118:33623. Connection refused.\n",
      "\n",
      "Exception in thread ray_import_thread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/site-packages/redis/connection.py\", line 177, in _read_from_socket\n",
      "    raise socket.error(SERVER_CLOSED_CONNECTION_ERROR)\n",
      "OSError: Connection closed by server.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/site-packages/redis/client.py\", line 2408, in _execute\n",
      "    return command(*args)\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/site-packages/redis/connection.py\", line 624, in read_response\n",
      "    response = self._parser.read_response()\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/site-packages/redis/connection.py\", line 284, in read_response\n",
      "    response = self._buffer.readline()\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/site-packages/redis/connection.py\", line 216, in readline\n",
      "    self._read_from_socket()\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/site-packages/redis/connection.py\", line 191, in _read_from_socket\n",
      "    (e.args,))\n",
      "redis.exceptions.ConnectionError: Error while reading from socket: ('Connection closed by server.',)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/site-packages/redis/connection.py\", line 484, in connect\n",
      "    sock = self._connect()\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/site-packages/redis/connection.py\", line 541, in _connect\n",
      "    raise err\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/site-packages/redis/connection.py\", line 529, in _connect\n",
      "    sock.connect(socket_address)\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/threading.py\", line 914, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/threading.py\", line 862, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/site-packages/ray/import_thread.py\", line 70, in _run\n",
      "    msg = import_pubsub_client.get_message()\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/site-packages/redis/client.py\", line 2513, in get_message\n",
      "    response = self.parse_response(block=False, timeout=timeout)\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/site-packages/redis/client.py\", line 2430, in parse_response\n",
      "    return self._execute(connection, connection.read_response)\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/site-packages/redis/client.py\", line 2415, in _execute\n",
      "    connection.connect()\n",
      "  File \"/opt/conda/envs/flow-latest/lib/python3.5/site-packages/redis/connection.py\", line 489, in connect\n",
      "    raise ConnectionError(self._error_message(e))\n",
      "redis.exceptions.ConnectionError: Error 111 connecting to 169.237.32.118:33623. Connection refused.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/envs/flow-latest/lib/python3.5/site-packages/ray/worker.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_ids, num_returns, timeout)\u001b[0m\n\u001b[1;32m   2312\u001b[0m             \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2313\u001b[0;31m             \u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_task_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2314\u001b[0m         )\n",
      "\u001b[0;32mpython/ray/_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.RayletClient.wait\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpython/ray/_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: [RayletClient] Raylet connection closed.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-62030d12fcba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0;34m\"training_iteration\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnum_iter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         },\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;34m\"config\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     }   \n\u001b[1;32m     13\u001b[0m })\n",
      "\u001b[0;32m/opt/conda/envs/flow-latest/lib/python3.5/site-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun_experiments\u001b[0;34m(experiments, search_alg, scheduler, with_server, server_port, verbose, resume, queue_trials, reuse_actors, trial_executor, raise_on_failed_trial)\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0mreuse_actors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreuse_actors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0mtrial_executor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m             raise_on_failed_trial=raise_on_failed_trial)\n\u001b[0m\u001b[1;32m    312\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/flow-latest/lib/python3.5/site-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, stop, config, resources_per_trial, num_samples, local_dir, upload_dir, trial_name_creator, loggers, sync_function, checkpoint_freq, checkpoint_at_end, export_formats, max_failures, restore, search_alg, scheduler, with_server, server_port, verbose, resume, queue_trials, reuse_actors, trial_executor, raise_on_failed_trial)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0mlast_debug\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_finished\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlast_debug\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mDEBUG_PRINT_INTERVAL\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/flow-latest/lib/python3.5/site-packages/ray/tune/trial_runner.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_running_trials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtrial\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trials\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/flow-latest/lib/python3.5/site-packages/ray/tune/trial_runner.py\u001b[0m in \u001b[0;36m_process_events\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_process_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m         \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next_available_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mwarn_if_slow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"process_trial\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/flow-latest/lib/python3.5/site-packages/ray/tune/ray_trial_executor.py\u001b[0m in \u001b[0;36mget_next_available_trial\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0;31m# See https://github.com/ray-project/ray/issues/4211 for details.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mresult_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshuffled_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m         \u001b[0mwait_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait_time\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mNONTRIVIAL_WAIT_TIME_THRESHOLD_S\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/flow-latest/lib/python3.5/site-packages/ray/worker.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_ids, num_returns, timeout)\u001b[0m\n\u001b[1;32m   2311\u001b[0m             \u001b[0mtimeout_milliseconds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2312\u001b[0m             \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2313\u001b[0;31m             \u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_task_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2314\u001b[0m         )\n\u001b[1;32m   2315\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mready_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tune.run_experiments({\n",
    "    exp_name: {\n",
    "        \"run\": GailTrainer,\n",
    "        \"env\": env_name,\n",
    "        \"checkpoint_freq\": 5,\n",
    "        \"max_failures\": 999,\n",
    "        \"num_samples\": 1,\n",
    "        \"stop\": {\n",
    "            \"training_iteration\": num_iter\n",
    "        },\n",
    "        \"config\": config\n",
    "    }   \n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "varInspector": {
   "cols": {
    "lenName": "50",
    "lenType": "50",
    "lenVar": "50"
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
