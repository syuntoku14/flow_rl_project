Traceback (most recent call last):
  File "/opt/conda/envs/flow/lib/python3.5/site-packages/ray/tune/trial_runner.py", line 261, in _process_events
    result = self.trial_executor.fetch_result(trial)
  File "/opt/conda/envs/flow/lib/python3.5/site-packages/ray/tune/ray_trial_executor.py", line 211, in fetch_result
    result = ray.get(trial_future[0])
  File "/opt/conda/envs/flow/lib/python3.5/site-packages/ray/worker.py", line 2386, in get
    raise value
ray.worker.RayTaskError: [36mray_PPOAgent:train()[39m (pid=8195, host=flow-main)
  File "/opt/conda/envs/flow/lib/python3.5/site-packages/ray/rllib/agents/agent.py", line 244, in __init__
    Trainable.__init__(self, config, logger_creator)
  File "/opt/conda/envs/flow/lib/python3.5/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/opt/conda/envs/flow/lib/python3.5/site-packages/ray/rllib/agents/agent.py", line 312, in _setup
    self._init()
  File "/opt/conda/envs/flow/lib/python3.5/site-packages/ray/rllib/agents/ppo/ppo.py", line 75, in _init
    self.env_creator, self._policy_graph)
  File "/opt/conda/envs/flow/lib/python3.5/site-packages/ray/rllib/agents/agent.py", line 413, in make_local_evaluator
    config["local_evaluator_tf_session_args"]
  File "/opt/conda/envs/flow/lib/python3.5/site-packages/ray/rllib/agents/agent.py", line 533, in _make_evaluator
    output_creator=output_creator)
  File "/opt/conda/envs/flow/lib/python3.5/site-packages/ray/rllib/evaluation/policy_evaluator.py", line 294, in __init__
    self.env, make_env=make_env, num_envs=num_envs)
  File "/opt/conda/envs/flow/lib/python3.5/site-packages/ray/rllib/env/async_vector_env.py", line 73, in wrap_async
    make_env=make_env, existing_envs=[env], num_envs=num_envs)
  File "/opt/conda/envs/flow/lib/python3.5/site-packages/ray/rllib/env/async_vector_env.py", line 283, in __init__
    self.env_states = [_MultiAgentEnvState(env) for env in self.envs]
  File "/opt/conda/envs/flow/lib/python3.5/site-packages/ray/rllib/env/async_vector_env.py", line 283, in <listcomp>
    self.env_states = [_MultiAgentEnvState(env) for env in self.envs]
  File "/opt/conda/envs/flow/lib/python3.5/site-packages/ray/rllib/env/async_vector_env.py", line 327, in __init__
    self.reset()
  File "/opt/conda/envs/flow/lib/python3.5/site-packages/ray/rllib/env/async_vector_env.py", line 345, in reset
    self.last_obs = self.env.reset()
  File "/headless/flow/flow/multiagent_envs/merge.py", line 452, in reset
    return super().reset()
  File "/headless/flow/flow/multiagent_envs/merge.py", line 211, in reset
    return super().reset()
  File "/headless/flow/flow/multiagent_envs/multiagent_env.py", line 244, in reset
    observation, _, _, _ = self.step(rl_actions=None)
  File "/headless/flow/flow/multiagent_envs/multiagent_env.py", line 107, in step
    states = self.get_state()
  File "/headless/flow/flow/multiagent_envs/merge.py", line 395, in get_state
    obs = super().get_state(rl_id, **kwargs)
  File "/headless/flow/flow/multiagent_envs/merge.py", line 326, in get_state
    bottom_density = np.sum(self.k.vehicle.get_length(bottom_car_ids)) / bottom_length
NameError: name 'bottom_car_ids' is not defined

